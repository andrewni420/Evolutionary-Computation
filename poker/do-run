#! /bin/sh
#SBATCH --partition gpu-a100-q
#SBATCH --gres=gpu:a100:1
#SBATCH --cpus-per-task=1
#SBATCH --time=00:30:00
#SBATCH --mem=3GB
module load amh-clojure
module load cuda10.2/toolkit
export DJL_DEFAULT_ENGINE=PyTorch
export MXNET_ENGINE_TYPE=NaiveEngine
export OMP_NUM_THREADS=1
python -c 'import torch; print(torch.cuda.get_device_name(torch.cuda.current_device()))'
srun ./run-file.clj

#! /bin/sh
#SBATCH --cpus-per-task=116
#SBATCH --time=10:00:00
#SBATCH --output=ERL-25p25g6b500nsym100l0.5s-%j.out
#SBATCH --error=ERL-25p25g6b500nsym100l0.5s-%j.err
module load amh-clojure
export DJL_DEFAULT_ENGINE=PyTorch
export MXNET_ENGINE_TYPE=NaiveEngine
export OMP_NUM_THREADS=1
srun ./run-file.clj

#!/bin/sh
#SBATCH -n 200
module load cm-pmix4/4.1.1
module load openmpi4/gcc/4.1.
module load amh-clojure
srun --mpi=pmix python -c "from mpi4py import MPI; print(MPI.COMM_WORLD.Get_rank())"
